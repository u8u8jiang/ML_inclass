{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import models, layers, regularizers\n",
    "from keras.datasets import mnist\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#各項函數\n",
    "layersDense1= 512 #第一層 hidden nodes\n",
    "activation1= 'relu' #第一層分類器 Classifier \n",
    "layersDense2= 10 #第二層 hidden nodes\n",
    "activation2= 'relu' #第二層分類器 Classifier\n",
    "outputnums= 10 #output nodes\n",
    "activation3= 'softmax' #output分類器 Classifier\n",
    "\n",
    "compileoptimizer= 'rmsprop'\n",
    "compileloss= 'categorical_crossentropy'  #可改用 mse\n",
    "compilemetrics= ['accuracy'] #可改用 ['mae']\n",
    "epochsnum= 5\n",
    "batchsize= 128\n",
    "lablenumber= 1\n",
    "\n",
    "# 讀入mnist資料集中的訓練資料及測試資料\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# 資料預處理及訓練,train資料大小60000,test資料大小10000,像素28*28\n",
    "train_images1 = train_images.reshape((60000, 28 * 28))\n",
    "train_images1 = train_images1.astype('float32') / 255\n",
    "test_images1 = test_images.reshape((10000, 28 * 28))\n",
    "test_images1 = test_images1.astype('float32') / 255\n",
    "train_labels_categ = to_categorical(train_labels)\n",
    "test_labels_categ = to_categorical(test_labels)\n",
    "kernelregularizer = regularizers.l1(0.01)\n",
    "\n",
    "# 編譯模型\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(layersDense1, kernel_regularizer = kernelregularizer,  activation= activation1, input_shape=(28*28,)))\n",
    "network.add(layers.Dense(layersDense2, activation= activation2))\n",
    "network.add(layers.Dropout(1)) #dropout layer\n",
    "network.add(layers.Dense(outputnums, activation= activation3))\n",
    "network.compile(optimizer= compileoptimizer,\n",
    "                loss= compileloss,\n",
    "                metrics= compilemetrics)\n",
    "\n",
    "#訓練神經網路\n",
    "history = network.fit(train_images1, train_labels_categ, epochs= epochsnum, batch_size= batchsize, \n",
    "                      validation_data=(test_images1, test_labels_categ))\n",
    "\n",
    "# Performance\n",
    "prediction = network.predict_classes(test_images1)\n",
    "crosstablex = pd.crosstab(test_labels, prediction,\n",
    "            rownames=['label'], colnames=['predict'])\n",
    "accuracyscore = accuracy_score(test_labels, prediction)\n",
    "\n",
    "for i in range(len(test_labels)):\n",
    "    if (test_labels[i] == lablenumber) & (test_labels[i] != prediction[i]):\n",
    "        print('when ', i, ': test_labels is ', test_labels[i], ', but predict ', prediction[i])\n",
    "        plt.imshow(test_images[i,:,:], cmap = plt.cm.gray) \n",
    "        plt.show()\n",
    "\n",
    "print('layers1: %2d, '%layersDense1)\n",
    "        \n",
    "print(network.predict_classes(test_images1))\n",
    "print(network.predict(test_images1))\n",
    "print(prediction)\n",
    "print(crosstablex)\n",
    "print(accuracyscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
